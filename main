{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":643971,"sourceType":"datasetVersion","datasetId":319080}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/brunopascoa/taa-t2-107418-108298?scriptVersionId=178579612\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Step 0: Setup","metadata":{}},{"cell_type":"markdown","source":"## Installing dependencies","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"%%capture\n!pip install tensorflow\n!pip install keras\n!pip install pydot\n!pip install Augmentor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing libraries","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore',category=FutureWarning)\nwarnings.filterwarnings('ignore',category=DeprecationWarning)\n\nimport pandas as pd\n\n# Import relevant libraries\nimport pathlib\nimport numpy as np\nfrom keras import layers, Sequential\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, MaxPool2D\nfrom keras.models import Model\nfrom keras.preprocessing import image\n\nfrom tensorflow.python.keras.utils import layer_utils\nfrom tensorflow.python.keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom tensorflow.keras.utils import plot_model\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\n\nfrom keras.optimizers import Adam\n\nfrom keras.metrics import F1Score\n\nfrom sklearn.metrics import confusion_matrix,roc_curve\n\nfrom keras.preprocessing import image\n\nimport Augmentor \n\nimport tensorflow as tf\nimport os\n\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_height = 180\nimg_width = 180\nnum_classes=9","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Allow gpu usage\ngpus = tf.config.experimental.list_physical_devices('GPU')\nprint(gpus)\ntry:\n    tf.config.experimental.set_memory_growth = True\nexcept Exception as ex:\n    print(e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining Hyperparameters","metadata":{}},{"cell_type":"code","source":"output_name=\"cnn.csv\" #the file where the results are appended to, if trying architectures besides CNN, a different file is to serve as input\nheaders=[\"batch_size\",\"epochs\",\"padding\",\"num_filters\",\"filter_sizes\",\"strides\",\"validation_split\",\"optimizer\",\"loss_function\",\"metrics\",\"result\",\"loss\"]\n\nbatch_size = 25\nepochs=40\n\n\npadding=[(3,3)]\nnum_filters=[32]\nfilter_size=[(7,7)]\nstrides=[(1,1)]\n\nvalidation_split=0.2\n\noptimizer=\"adam\"\nloss=\"categorical_crossentropy\"\nmetrics=[\"accuracy\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Balance dataset","metadata":{}},{"cell_type":"code","source":"data_dir_train = pathlib.Path(\"../input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\")\ndata_dir_test = pathlib.Path(\"../input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Test/\")\n\nimage_count_train = len(list(data_dir_train.glob('*/*.jpg')))\nimage_count_test = len(list(data_dir_test.glob('*/*.jpg')))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir_train,\n    seed=107418,\n    image_size=(img_height, img_width),\n    batch_size=batch_size)\nclass_names=test_ds.class_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_to_training_dataset = '../input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train/'\nimport Augmentor\nfor i in class_names:\n    p = Augmentor.Pipeline(path_to_training_dataset + i, output_directory='/kaggle/working/dataset/train/'+i)\n    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n    p.sample(1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load dataset\nCode adapted from [Skin Cancer Detection](https://www.kaggle.com/code/manafabduljabbar/skin-cancer-detection)","metadata":{}},{"cell_type":"markdown","source":"## Augment dataset\nUsing Augmenter to make all classes roughly have the same number of examples","metadata":{}},{"cell_type":"code","source":"output_directory=\"/kaggle/working\"\n\nimport Augmentor\nfor i in class_names:\n    p = Augmentor.Pipeline(\"../input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\" + i, output_directory=output_directory+'/dataset/train/'+i)\n    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n    p.sample(1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  output_directory+\"/dataset/train\",\n  seed=107418,\n  validation_split = validation_split,\n  subset = 'training',\n  image_size=(img_height, img_width),\n  batch_size=batch_size\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  output_directory,\n  seed=107418,\n  validation_split = validation_split,\n  subset = 'validation',\n  image_size=(img_height, img_width),\n  batch_size=batch_size\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## One-hot encode datasets","metadata":{}},{"cell_type":"code","source":"def one_hot_encode(image,label):\n    label1hot=tf.one_hot(label,depth=num_classes)\n    return image,label1hot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds=train_ds.map(one_hot_encode)\nvalidation_ds=validation_ds.map(one_hot_encode)\ntest_ds=test_ds.map(one_hot_encode)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define model","metadata":{}},{"cell_type":"code","source":"model = Sequential([layers.experimental.preprocessing.Rescaling(1.0/255,input_shape=(img_height,img_width,3))])\n\nmodel.add(Conv2D(32, 3,padding=\"same\",activation='relu'))\nmodel.add(MaxPool2D())\n\nmodel.add(Flatten())\nmodel.add(Dense(1024,activation=\"relu\"))\nmodel.add(Dense(units=num_classes, activation= 'softmax'))\n\n\nmodel.compile(optimizer=optimizer,loss=loss,metrics=metrics)\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 1: training","metadata":{}},{"cell_type":"code","source":"model.fit(train_ds,epochs=epochs,validation_data=validation_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2: testing","metadata":{}},{"cell_type":"code","source":"results=model.evaluate(test_ds)\nmetric_result=results[1]\nloss=results[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3: display results","metadata":{}},{"cell_type":"markdown","source":"## Confusion matrix","metadata":{}},{"cell_type":"code","source":"predictions=model.predict(test_ds)\npredictions=np.argmax(predictions,axis=-1)\ny_true = np.concatenate([y for x, y in test_ds], axis=0)\ny_true=np.argmax(y_true,axis=-1)\ncm=confusion_matrix(y_true,predictions)\nprint(cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save to .csv","metadata":{}},{"cell_type":"code","source":"output=[batch_size,epochs,str(padding),str(num_filters),str(filter_size),str(strides),validation_split,optimizer,loss,str(metrics),metric_result,loss]\noutput=pd.DataFrame(output)\nexists = os.path.isfile(filename)\n\n  # Open the file with appropriate header handling\nwith open(filename, mode) as f:\n    if not exists:\n        output.to_csv(f, header=headers)\n    else:\n        output.to_csv(f, mode=\"a\",header=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}